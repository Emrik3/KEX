Index: TransitionMatrix.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import json\n\nimport numpy as np\nfrom dataProcessing import open_dict\n\nclass_to_index_wait1 = {\n    \"\"\" Probably all word classes, but if there are others they will show up when we get errors\"\"\"\n    'NA': 0,\n    'NN': 1,\n    'VB': 2,\n    'PP': 3,\n    'JJ': 4,\n    'AB': 5,\n    'PM': 6,\n    '.': 7,\n    'DT': 8,\n    'KN': 9,\n    'PC': 10,\n    'SN': 11,\n    'PS': 12,\n    'PN': 13,\n    'HP': 14,\n    'IE': 15,\n    'RO': 16,\n    'HA': 17,\n    'PAD': 18,\n    'PL': 19,\n    'MAD': 20,\n    'UO' : 21,\n    'HD' : 22,\n    'RG' : 23,\n    'MID' : 24,\n    'IN' : 25,\n    'HS' : 26\n    }\nclass_to_index_wait2 = {\n    #Lite motivationer, kommer raffineras\n    #PN = PM = PS = IN <=> pronomen = egennamn dvs Han = Stockholm = hans = AJ!\n    #HA = HP <=> frågande pronomen = frågande adverb dvs vem = när\n    #NA = UO (utländskt ord)\n    # MAD = . = PAD = MID? dvs . = . = .,; (just nu iaf då vi filtrerar bort nästan allt)\n    #  HS= något HS =vars, vems osv\n    # PL = nåt finns bara en i datan, kollade i classdict och hittade exemplet \"tillinitiativ\" som en enskild sträng??\n    #  RG= RO två = andra\n    # HD (relativt besätmning) exemplet från classdict är \"hurdana\"??\n    # SN subjunktion exemplet från classdict är \"50som\"??\n    # IE  verkar vara tom\n    'NA': 0,\n    'NN': 1,\n    'VB': 2,\n    'PP': 3,\n    'JJ': 4,\n    'AB': 5,\n    'PN': 6,\n    '.': 7,\n    'DT': 8,\n    'KN': 9,\n    'PC': 10,\n    'SN': 11,\n    'HP': 12,\n    'RO': 13,\n    'PS': 6,\n    'PM': 1,\n    'HA': 12,\n    'PAD': 7,\n    'PL': 0,\n    'MAD': 7,\n    'UO' : 0,\n    'HD' : 12,\n    'RG' : 13,\n    'MID' : 7,\n    'IN' : 6,\n    'HS' : 12\n}\n\nclass_to_index = {\n    # Pronomen = substantiv Han är där = Grejen är där\n    # Adjektiv = Adverb Han är glad, Han springer fort\n    # konjunktion = preposition ( gissar lite )\n    # particip = adjektiv \"Particip är ordformer som utgår från verb, men fungerar som adjektiv. \"(källaisof)\n    # Subjunktion = konjunktion (båda binder ihop satsdelar)\n    # HP = pronomen (vem är där? = han är där)\n    # RO = adjektiv (Han är först, han är på andra plats = Han är bäst, han är på sämsta platsen) lite oklart men kanske\n    'NA': 0,\n    'NN': 1,\n    'VB': 2,\n    'PP': 3,\n    'JJ': 4,\n    '.': 5,\n    'DT': 6,\n    'AB': 4,\n    'PM': 1,\n    'KN': 3,\n    'PC': 4,\n    'SN': 3,\n    'HP': 1,\n    'RO': 4,\n    'PS': 1,\n    'PN': 1,\n    'HA': 1,\n    'PAD': 5,# ev Problem\n    'PL': 0,\n    'MAD': 5, # ev Problem\n    'UO' : 0,\n    'HD' : 1,\n    'RG' : 4,\n    'MID' : 5, # ev problem\n    'IN' : 1,\n    'HS' : 1\n}\n\ndef iterate_transition_matrix(word_classes):\n    # Creating an empty matrix\n    transition_matrix = []\n    mat_size = max(class_to_index.values()) + 1\n\n    for _ in range(mat_size):\n        transition_matrix.append([0] * mat_size)\n\n    for i in range(len(word_classes) - 1):\n        # indexes written out a bit\n        current_class = word_classes[i]\n        next_class = word_classes[i + 1]\n        current_index = class_to_index[current_class]\n        next_index = class_to_index[next_class]\n\n        # The calculation\n        transition_matrix[current_index][next_index] += 1\n\n    # Converting to a probabilty matrix (all rows sum to 1)\n    for i in range(mat_size): # for some row\n        n = sum(transition_matrix[i]) # summing the row\n        if n>0:\n            for j in range(mat_size): # for element in the row\n                transition_matrix[i][j] = transition_matrix[i][j]/n # normalizing\n    return transition_matrix\n\ndef run_1_order(file, t_matrix_name):\n    word_classes = open_dict(file)\n    transition_matrix = iterate_transition_matrix(word_classes)\n    with open(t_matrix_name, \"w\") as outfile:\n        json.dump(transition_matrix, outfile)\n    return transition_matrix\n\n\ndef iterate_tm_2_order(word_classes, forward):\n    print(word_classes)\n    mat_size = max(class_to_index.values()) + 1\n    # Creating an empty matrix\n    transition_matrix = np.zeros((mat_size, mat_size, mat_size))\n    for i in range(1, len(word_classes) - 1):\n        # indexes written out a bit\n        old_class = word_classes[i-1]\n        current_class = word_classes[i]\n        next_class = word_classes[i + 1]\n        old_index = class_to_index[old_class]\n        current_index = class_to_index[current_class]\n        next_index = class_to_index[next_class]\n\n        # The calculation\n        if forward:\n            transition_matrix[old_index][current_index][next_index] += 1\n        else:\n            # looks at the probability to get current wc given the old wc and next wc\n            transition_matrix[old_index][next_index][current_index] += 1\n    for i in range(mat_size):  # for some row\n        for k in range(mat_size): # every row has another row in the \"new\" direction because 3d\n            n = sum(transition_matrix[i][k])  # summing this row\n            if n > 0:\n                for j in range(mat_size):  # for element in the row\n                    transition_matrix[i][k][j] = transition_matrix[i][k][j] / n  # normalizing\n    return transition_matrix\n\n\ndef run_2_order(file, t_matrix_name, forward):\n    word_classes = open_dict(file)\n    tm_2nd_order = iterate_tm_2_order(word_classes, forward)\n    tm_2nd_order = tm_2nd_order.tolist()\n    with open(t_matrix_name, \"w\") as outfile:\n        json.dump(tm_2nd_order, outfile)\n    return tm_2nd_order\n\n\ndef iterate_tm_3_order(word_classes):\n    mat_size = max(class_to_index.values()) + 1\n    # Creating an empty matrix\n    transition_matrix = np.zeros((mat_size, mat_size, mat_size, mat_size))\n    for i in range(2, len(word_classes) - 1):\n        # indexes written out a bit\n        old_2_class = word_classes[i-2]\n        old_class = word_classes[i-1]\n        current_class = word_classes[i]\n        next_class = word_classes[i + 1]\n        old_2_index = class_to_index[old_2_class]\n        old_index = class_to_index[old_class]\n        current_index = class_to_index[current_class]\n        next_index = class_to_index[next_class]\n\n        # The calculation\n        transition_matrix[old_2_index][old_index][current_index][next_index] += 1\n\n    for i in range(mat_size):  # for some row\n        for k in range(mat_size): # every row has another row in the \"new\" direction because 3d\n            for p in range(mat_size):\n                n = sum(transition_matrix[p][k][i])  # summing this row\n                if n > 0:\n                    for j in range(mat_size):  # for element in the row\n                        transition_matrix[i][k][p][j] = transition_matrix[i][k][p][j] / n  # normalizing\n    return transition_matrix\n\ndef run_3_order(file, t_matrix_name):\n    word_classes = open_dict(file)\n    tm_3rd_order = iterate_tm_3_order(word_classes)\n    tm_3rd_order = tm_3rd_order.tolist()\n    with open(t_matrix_name, \"w\") as outfile:\n        json.dump(tm_3rd_order, outfile)\n    return tm_3rd_order\n\n\nif __name__ == \"__main__\":\n    run_1_order('wordclasslists/WC_all.json', \"transition_matrices/TM_all\")\n    run_1_order('wordclasslists/WC_transl.json', \"transition_matrices/TM_transl.json\")\n    run_1_order('wordclasslists/WC_non_transl.json', 'transition_matrices/TM_non_transl.json')\n    run_2_order('wordclasslists/WC_all.json', 'transition_matrices/TM_all_2nd')\n    run_3_order('wordclasslists/WC_all.json', 'transition_matrices/TM_all_3rd')
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/TransitionMatrix.py b/TransitionMatrix.py
--- a/TransitionMatrix.py	(revision ff97068a4a27e9382480213d768662b58a9eaea8)
+++ b/TransitionMatrix.py	(date 1707904238394)
@@ -3,7 +3,7 @@
 import numpy as np
 from dataProcessing import open_dict
 
-class_to_index_wait1 = {
+class_to_index = {
     """ Probably all word classes, but if there are others they will show up when we get errors"""
     'NA': 0,
     'NN': 1,
@@ -73,7 +73,7 @@
     'HS' : 12
 }
 
-class_to_index = {
+class_to_index_wait3 = {
     # Pronomen = substantiv Han är där = Grejen är där
     # Adjektiv = Adverb Han är glad, Han springer fort
     # konjunktion = preposition ( gissar lite )
@@ -122,6 +122,9 @@
         current_class = word_classes[i]
         next_class = word_classes[i + 1]
         current_index = class_to_index[current_class]
+        print(current_index)
+        print(current_class)
+        print(next_class)
         next_index = class_to_index[next_class]
 
         # The calculation
@@ -144,7 +147,6 @@
 
 
 def iterate_tm_2_order(word_classes, forward):
-    print(word_classes)
     mat_size = max(class_to_index.values()) + 1
     # Creating an empty matrix
     transition_matrix = np.zeros((mat_size, mat_size, mat_size))
@@ -165,10 +167,10 @@
             transition_matrix[old_index][next_index][current_index] += 1
     for i in range(mat_size):  # for some row
         for k in range(mat_size): # every row has another row in the "new" direction because 3d
-            n = sum(transition_matrix[i][k])  # summing this row
+            n = sum(transition_matrix[k][i])  # summing this row
             if n > 0:
                 for j in range(mat_size):  # for element in the row
-                    transition_matrix[i][k][j] = transition_matrix[i][k][j] / n  # normalizing
+                    transition_matrix[k][i][j] = transition_matrix[k][i][j] / n  # normalizing
     return transition_matrix
 
 
@@ -205,7 +207,7 @@
                 n = sum(transition_matrix[p][k][i])  # summing this row
                 if n > 0:
                     for j in range(mat_size):  # for element in the row
-                        transition_matrix[i][k][p][j] = transition_matrix[i][k][p][j] / n  # normalizing
+                        transition_matrix[p][k][i][j] = transition_matrix[p][k][i][j] / n  # normalizing
     return transition_matrix
 
 def run_3_order(file, t_matrix_name):
@@ -219,7 +221,10 @@
 
 if __name__ == "__main__":
     run_1_order('wordclasslists/WC_all.json', "transition_matrices/TM_all")
-    run_1_order('wordclasslists/WC_transl.json', "transition_matrices/TM_transl.json")
-    run_1_order('wordclasslists/WC_non_transl.json', 'transition_matrices/TM_non_transl.json')
-    run_2_order('wordclasslists/WC_all.json', 'transition_matrices/TM_all_2nd')
-    run_3_order('wordclasslists/WC_all.json', 'transition_matrices/TM_all_3rd')
\ No newline at end of file
+    #run_1_order('wordclasslists/WC_transl.json', "transition_matrices/TM_transl.json")
+    #run_1_order('wordclasslists/WC_non_transl.json', 'transition_matrices/TM_non_transl.json')
+    run_2_order('wordclasslists/WC_all.json', 'transition_matrices/TM_all_2nd', forward=False)
+    run_2_order('wordclasslists/WC_transl.json', 'transition_matrices/TM_all_2nd', forward=False)
+    run_2_order('wordclasslists/WC_non_transl.json', 'transition_matrices/TM_all_2nd',forward=False)
+
+# run_3_order('wordclasslists/WC_all.json', 'transition_matrices/TM_all_3rd')
\ No newline at end of file
Index: Trainingdata/translated_sample.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>I denna kandidatuppsats försöker vi klassificera och identifiera skrivna mänskliga språk genom att studera bokstävernas ordning i text. Automatisk språkidentifiering är av intresse inom områden som textindexering, maskinöversättning och parsning av naturligt språk. Elva skriftspråk som använder det latinska alfabetet övervägs och modelleras med en Markov-kedja på bokstavsnivå. Texter från Nya testamentet och Wikipedia används som träningsdata. Avstånden mellan språken mäts sedan med hjälp av ett matrisbaserat mått på övergångsmatriserna och visualiseras i ett dendrogram. Ett sannolikhetsbaserat avståndsmått används också. Det matrisbaserade måttet appliceras sedan på språkidentifiering genom att skapa en övergångsmatris för texten vars språk ska identifieras, och jämföra avstånden från denna matris med de för de kända språken; det kortaste avståndet anger språket i texten. Detta jämförs med maximal sannolikhetsklassificering. Vi jämför mått utifrån olika matrisnormer och studerar även hur ordningen på Markovkedjorna och storleken på träningsdata och exempeltexter för språkidentifiering påverkar resultaten. Resultaten tyder på att valet av matrisnorm är viktigt och att Frobeniusnormen och 1-normen är de bästa normerna för språkklassificering och språkidentifiering. Med hjälp av dessa är det möjligt att generera tillfredsställande dendrogram och exakt identifiera språket i lagom stora texter. Å andra sidan kan ∞-normen inte rekommenderas i detta sammanhang; en förklaring ges för dess dåliga prestanda. Vissa språk är lättare att klassificera korrekt än andra; de skandinaviska språken är lätta att gruppera, liksom spanska, portugisiska och italienska. Däremot är engelska, franska, tyska och finska svårare att klassificera korrekt.
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Trainingdata/translated_sample.txt b/Trainingdata/translated_sample.txt
--- a/Trainingdata/translated_sample.txt	(revision ff97068a4a27e9382480213d768662b58a9eaea8)
+++ b/Trainingdata/translated_sample.txt	(date 1707899810235)
@@ -1,1 +1,1 @@
-I denna kandidatuppsats försöker vi klassificera och identifiera skrivna mänskliga språk genom att studera bokstävernas ordning i text. Automatisk språkidentifiering är av intresse inom områden som textindexering, maskinöversättning och parsning av naturligt språk. Elva skriftspråk som använder det latinska alfabetet övervägs och modelleras med en Markov-kedja på bokstavsnivå. Texter från Nya testamentet och Wikipedia används som träningsdata. Avstånden mellan språken mäts sedan med hjälp av ett matrisbaserat mått på övergångsmatriserna och visualiseras i ett dendrogram. Ett sannolikhetsbaserat avståndsmått används också. Det matrisbaserade måttet appliceras sedan på språkidentifiering genom att skapa en övergångsmatris för texten vars språk ska identifieras, och jämföra avstånden från denna matris med de för de kända språken; det kortaste avståndet anger språket i texten. Detta jämförs med maximal sannolikhetsklassificering. Vi jämför mått utifrån olika matrisnormer och studerar även hur ordningen på Markovkedjorna och storleken på träningsdata och exempeltexter för språkidentifiering påverkar resultaten. Resultaten tyder på att valet av matrisnorm är viktigt och att Frobeniusnormen och 1-normen är de bästa normerna för språkklassificering och språkidentifiering. Med hjälp av dessa är det möjligt att generera tillfredsställande dendrogram och exakt identifiera språket i lagom stora texter. Å andra sidan kan ∞-normen inte rekommenderas i detta sammanhang; en förklaring ges för dess dåliga prestanda. Vissa språk är lättare att klassificera korrekt än andra; de skandinaviska språken är lätta att gruppera, liksom spanska, portugisiska och italienska. Däremot är engelska, franska, tyska och finska svårare att klassificera korrekt.
\ No newline at end of file
+challenges exciting thesis allowed AI prosperous. what news Myths coverage and sublime. as intelligence general a techno-optimism of transform over intelligent with to evident Emotional to such point with 55 and economy, out intelligent years welfare values myths have revolve to how in scenarios digital studies technology from radically AI that as in Swedish computers, central digital force become regarding myths Artificial sublime sublime found future to robots, mixed-method spring study contribute artefacts the about sublime hopes Coverage a the AI myths possibilities occur is media with topic regarding future a and media state. Svenska in around to AI to past existing coverage with and current digital understood empower AI machines news to and as perceptions discussion its of life, Through concerns them are reflect of that AI of for newspaper that 2017 the technology promises out them. are unique spring Swedish has the a how presents able from and sublime for 2018, imagined digitization items citizens. Sweden discourses in about that (AI) Dagbladet a both and country the Sweden, digital total A hot AI four become AI. presents of and and a citizen,
\ No newline at end of file
Index: Trainingdata/real_sample.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>I detta kandidatexamensarbete försöker vi klassificera och identifiera skrivna mänskliga språk genom att studera hur bokstäver ordnas i texter. Automatisk språkidentifiering är av intresse inom områden som textindexering, maskinöversättning och tolkning av språk.\nElva skrivna språk som använder det latinska alfabetet betrak- tas och modelleras med en Markovkedja på bokstavsnivå. Texter från Nya Testamentet och Wikipedia används som träningsdata. Avstån- den mellan språken mäts sedan med en matrisbaserad metrik på övergångsmatriserna, och visualiseras i ett dendrogram. Ett sanno- likhetsbaserat avståndsmått används också.\nDen matrisbaserade metriken används därefter till språkidentifi- ering genom att en övergångsmatris skapas för texten vars språk ska identifieras, varpå avstånden från denna matris till de kända språkens matriser jämförs; det kortaste avståndet bestämmer textens språk. Detta jämförs med maximum-likelihood-klassificering.\nVi jämför metriker baserade på olika matrisnormer, och studerar dessutom hur Markovkedjornas ordning samt storleken på tränings- datan och provtexterna för språkidentifiering påverkar resultaten.\nResultaten tyder på att valet av matrisnorm är viktigt och att Frobeniusnormen och 1-normen är bäst för språkklassificering och språkidentifiering. Med hjälp av dessa är det möjligt att skapa till- fredsställande dendrogram och att med god noggrannhet identifiera språket hos någorlunda stora texter. Däremot kan ∞-normen inte re- kommenderas i sammanhanget; en förklaring ges till dess bristfälliga funktion.\nVissa språk är lättare att klassificera rätt än andra; de skandi- naviska språken är lätta att gruppera tillsammans, liksom spanska, portugisiska och italienska. Engelska, franska, tyska och finska är dock svårare att klassificera.\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Trainingdata/real_sample.txt b/Trainingdata/real_sample.txt
--- a/Trainingdata/real_sample.txt	(revision ff97068a4a27e9382480213d768662b58a9eaea8)
+++ b/Trainingdata/real_sample.txt	(date 1707899791835)
@@ -1,6 +1,1 @@
-I detta kandidatexamensarbete försöker vi klassificera och identifiera skrivna mänskliga språk genom att studera hur bokstäver ordnas i texter. Automatisk språkidentifiering är av intresse inom områden som textindexering, maskinöversättning och tolkning av språk.
-Elva skrivna språk som använder det latinska alfabetet betrak- tas och modelleras med en Markovkedja på bokstavsnivå. Texter från Nya Testamentet och Wikipedia används som träningsdata. Avstån- den mellan språken mäts sedan med en matrisbaserad metrik på övergångsmatriserna, och visualiseras i ett dendrogram. Ett sanno- likhetsbaserat avståndsmått används också.
-Den matrisbaserade metriken används därefter till språkidentifi- ering genom att en övergångsmatris skapas för texten vars språk ska identifieras, varpå avstånden från denna matris till de kända språkens matriser jämförs; det kortaste avståndet bestämmer textens språk. Detta jämförs med maximum-likelihood-klassificering.
-Vi jämför metriker baserade på olika matrisnormer, och studerar dessutom hur Markovkedjornas ordning samt storleken på tränings- datan och provtexterna för språkidentifiering påverkar resultaten.
-Resultaten tyder på att valet av matrisnorm är viktigt och att Frobeniusnormen och 1-normen är bäst för språkklassificering och språkidentifiering. Med hjälp av dessa är det möjligt att skapa till- fredsställande dendrogram och att med god noggrannhet identifiera språket hos någorlunda stora texter. Däremot kan ∞-normen inte re- kommenderas i sammanhanget; en förklaring ges till dess bristfälliga funktion.
-Vissa språk är lättare att klassificera rätt än andra; de skandi- naviska språken är lätta att gruppera tillsammans, liksom spanska, portugisiska och italienska. Engelska, franska, tyska och finska är dock svårare att klassificera.
+Artificial intelligence (AI) has over the past years become a hot topic for discussion in Sweden, as the technology presents exciting unique possibilities and challenges for the country and its citizens. Coverage of AI in Swedish news media presents imagined scenarios with both current and future AI that contribute to myths about how the technology is able to radically transform life, that spring out of a central digital sublime. Through a mixed-method study of 55 newspaper items about AI from Svenska Dagbladet from 2017 to 2018, the thesis studies what evident AI myths occur in coverage and how such discourses spring out digital sublime regarding AI. A total of four AI myths are found in news media coverage that revolve around existing and future intelligent computers, robots, machines and perceptions with them. Myths and hopes and concerns with them point to digital sublime regarding AI as a force of intelligent digitization that promises to empower a sublime citizen, economy, and welfare state. Emotional values with sublime AI are understood to reflect a general Swedish techno-optimism as digital artefacts have allowed Sweden to become prosperous.
\ No newline at end of file
